{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "24edaf81-ce8c-465d-9c40-825edb1ed14f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anik\\anaconda3\\envs\\Deep\\lib\\site-packages\\scipy\\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.1\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "import os\n",
    "import glob #tqdm\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import*\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "\n",
    "#Neural Network\n",
    "import tensorflow\n",
    "from tensorflow.keras.layers import Conv2D,Dense,AveragePooling2D, Flatten\n",
    "from tensorflow.keras.optimizers     import SGD\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "\n",
    "#visualization\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "#OpenCv\n",
    "import cv2\n",
    "\n",
    "\n",
    "#warning\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "43d85296-a65d-4ec4-839a-bf62719eefd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "testimageDatasetspath = \"E:/DeepLearning/Datasets/train\" \n",
    "datasetsNameTest = os.listdir(testimageDatasetspath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e772f1e7-a516-4624-9ba5-3db4ed745da5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[55, 71, 40, 27, 34, 51, 60, 67, 94, 15, 82, 79, 4, 66, 27, 79, 79, 11, 74, 87]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = list(np.random.randint(0,100,size=20))\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "37828e15-9dbb-4971-9527-f4a9153485ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['cat.0.jpg', 'cat.1.jpg', 'cat.10.jpg', ..., 'dog.998.jpg',\n",
       "       'dog.999.jpg', 'dogs'], dtype='<U11')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(datasetsNameTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "97c6b795-4467-41c0-a0ad-9bde4d7bffe3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasetsNameTest.index(\"dog.999.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "189360c7-3065-4eae-8c39-ba13a15c7919",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_width = 28\n",
    "image_height = 28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "79d1a0d1-3c70-4367-8042-640fb2645488",
   "metadata": {},
   "outputs": [],
   "source": [
    "def imageFeatureExtract(image,size =(28,28)):\n",
    "    img = cv2.resize(image,size)\n",
    "    gray = cv2.cvtColor(img,cv2.COLOR_RGB2GRAY)\n",
    "    gray = np.expand_dims(gray,2) #(28,28,1)\n",
    "    return gray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "76839d29-ec55-4ad6-9789-69f54cd974ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "Datasetspath = \"E:/DeepLearning/Datasets/train\"\n",
    "datasetPath = os.path.join(Datasetspath , \"*g\")\n",
    "fileRead = glob.glob(datasetPath)\n",
    "\n",
    "data =[]\n",
    "category_or_class = []\n",
    "\n",
    "for (i,file) in enumerate(fileRead):\n",
    "    image = cv2.imread(file)\n",
    "    feature = imageFeatureExtract(image)\n",
    "    data.append(feature)\n",
    "    classNames = file.split(os.path.sep)[-1].split(\".\")[0]\n",
    "    category_or_class.append(classNames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "babf0bc7-46f2-4abc-8ac7-671884b450dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Datasets Scalling\n",
    "data = np.array(data, dtype= np.uint8)\n",
    "labels = np.array(category_or_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6737f249-c1f9-4c69-8dec-722c29fb47ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 28, 28, 1)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b2b1d00c-2a95-4572-8121-65a12fd2ca63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['cat', 'dog'], dtype='<U3')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(category_or_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dedb838c-28b9-4b55-aaa2-b1eb6841b4e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(category_or_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "417c188e-7b23-4431-b10e-0db9e2a4d7e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(category_or_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3eb1845-206c-4b20-9408-ab72fae5e20c",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Step 1:Label Encoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "61a74aae-6035-4427-8edc-1543885b4db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(category_or_class)\n",
    "list(le.classes_)\n",
    "classNames = le.transform(category_or_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9cdf959c-75a7-4a99-bbe2-b20a1fbf7c9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(classNames)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d6f9460-7847-4c8f-a72e-d8eb07fa1e6c",
   "metadata": {},
   "source": [
    "## Step 2: OneHotEnconding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0fcc0967-cc72-44bf-8c4f-498c1977b8fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "oneHotEncoder = OneHotEncoder(sparse= False)\n",
    "label_EncoderValue  = classNames.reshape(len(classNames), 1)\n",
    "oneHotEncoderValues = oneHotEncoder.fit_transform(label_EncoderValue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8a70b74d-76f8-4e21-af89-8c9f008628b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       ...,\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oneHotEncoderValues\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "69c76951-0ac7-4579-9df3-4d342ab3244b",
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train,X_test, Y_train,Y_test) = train_test_split(data, oneHotEncoderValues, test_size=0.2 ,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4b67c6c4-6070-4436-8b7d-c6baeb7bce41",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    " #1st layer\n",
    "model.add(Conv2D(6, kernel_size = (5,5) , strides = (1,1) , activation =\"tanh\", input_shape =(28,28,1),  padding =\"same\"))\n",
    "model.add(AveragePooling2D(pool_size  = (2,2),strides=(2,2),padding=\"valid\")) \n",
    "  \n",
    " #2nd layer\n",
    "model.add(Conv2D(16, kernel_size = (5,5) ,strides = (1,1), activation =\"tanh\", input_shape =(28,28,1), padding =\"valid\"))\n",
    "model.add(AveragePooling2D(pool_size  = (2,2),strides=(2,2),padding=\"valid\")) \n",
    "          \n",
    "   #flatten layer\n",
    "model.add(Flatten())\n",
    "          \n",
    "  #output layer \n",
    "model.add(Dense(120, activation= \"tanh\"))\n",
    "model.add(Dense(84, activation= \"tanh\"))          \n",
    "model.add(Dense(2, activation= \"softmax\"))          \n",
    "          \n",
    "          \n",
    "          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "384f0058-a8d0-48c1-94c5-c4d4408773f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer= \"adam\",\n",
    "             loss=\"categorical_crossentropy\",\n",
    "             metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "191b3b7c-ff3b-40ad-8506-932f0d8f8857",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 28, 28, 6)         156       \n",
      "                                                                 \n",
      " average_pooling2d (AverageP  (None, 14, 14, 6)        0         \n",
      " ooling2D)                                                       \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 10, 10, 16)        2416      \n",
      "                                                                 \n",
      " average_pooling2d_1 (Averag  (None, 5, 5, 16)         0         \n",
      " ePooling2D)                                                     \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 400)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 120)               48120     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 84)                10164     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 2)                 170       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 61,026\n",
      "Trainable params: 61,026\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "eac5b44d-68f7-49ac-9eaa-deee448a3bf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "50/50 [==============================] - 3s 14ms/step - loss: 0.7516 - accuracy: 0.5119 - val_loss: 0.6927 - val_accuracy: 0.5050\n",
      "Epoch 2/10\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 0.6781 - accuracy: 0.5781 - val_loss: 0.6656 - val_accuracy: 0.6000\n",
      "Epoch 3/10\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 0.6604 - accuracy: 0.6025 - val_loss: 0.6914 - val_accuracy: 0.6100\n",
      "Epoch 4/10\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 0.6326 - accuracy: 0.6375 - val_loss: 0.6882 - val_accuracy: 0.5750\n",
      "Epoch 5/10\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 0.6412 - accuracy: 0.6413 - val_loss: 0.6806 - val_accuracy: 0.5950\n",
      "Epoch 6/10\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 0.6087 - accuracy: 0.6719 - val_loss: 0.6999 - val_accuracy: 0.5675\n",
      "Epoch 7/10\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 0.6245 - accuracy: 0.6525 - val_loss: 0.6741 - val_accuracy: 0.6000\n",
      "Epoch 8/10\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 0.6107 - accuracy: 0.6544 - val_loss: 0.6981 - val_accuracy: 0.5900\n",
      "Epoch 9/10\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 0.5691 - accuracy: 0.7069 - val_loss: 0.7130 - val_accuracy: 0.5950\n",
      "Epoch 10/10\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 0.5626 - accuracy: 0.7044 - val_loss: 0.6903 - val_accuracy: 0.5925\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1573b94f520>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,Y_train,\n",
    "          epochs =10,\n",
    "          validation_data=(X_test,Y_test),verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7e5bb841-ce09-4ae1-9cb5-cbbefb629723",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNet_Model(Sequential):\n",
    "    \n",
    "    def __init__(self,input_shape,number_class):\n",
    "        super().__init__()\n",
    "        \n",
    "         #1st layer\n",
    "        self.add(Conv2D(6, kernel_size = (5,5) , strides = (1,1) , activation =\"tanh\", input_shape =input_shape,padding=\"same\"))\n",
    "        self.add(AveragePooling2D(pool_size  = (2,2),strides=(2,2),padding=\"valid\"))\n",
    "        \n",
    "        #2nd layer\n",
    "        self.add(Conv2D(16,kernel_size = (5,5) , strides = (1,1) , activation =\"tanh\",   padding =\"valid\"))\n",
    "        self.add(AveragePooling2D(pool_size  = (2,2),strides=(2,2),padding=\"valid\"))\n",
    "        \n",
    "        self.add(Flatten())\n",
    "        \n",
    "        self.add(Dense(120, activation= \"tanh\"))\n",
    "        self.add(Dense(84,activation=\"tanh\"))\n",
    "        self.add(Dense(number_class , activation=\"softmax\"))\n",
    "        \n",
    "        self.compile(optimizer= \"adam\",\n",
    "             loss=\"categorical_crossentropy\",\n",
    "             metrics=[\"accuracy\"])\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc5c5227-2781-4d94-8268-81caa018546e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ba7ed720-f8db-4739-9b5f-904e1795f1f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shapes = X_train[0].shape\n",
    "number_class = len(np.unique(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c4cdd11e-42f1-47b9-989c-d128b1e2bdf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"le_net__model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_2 (Conv2D)           (None, 28, 28, 6)         156       \n",
      "                                                                 \n",
      " average_pooling2d_2 (Averag  (None, 14, 14, 6)        0         \n",
      " ePooling2D)                                                     \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 10, 10, 16)        2416      \n",
      "                                                                 \n",
      " average_pooling2d_3 (Averag  (None, 5, 5, 16)         0         \n",
      " ePooling2D)                                                     \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 400)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 120)               48120     \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 84)                10164     \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 2)                 170       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 61,026\n",
      "Trainable params: 61,026\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "myModel =LeNet_Model(input_shapes,number_class)\n",
    "myModel.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3172519c-e3c7-45a6-97ff-96c1130528c2",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'keras.api._v2.keras.callbacks' has no attribute 'TensorBroad'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[1;32mIn [26]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[0;32m      3\u001b[0m logsData \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlogs/fit\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m datetime\u001b[38;5;241m.\u001b[39mdatetime\u001b[38;5;241m.\u001b[39mnow()\u001b[38;5;241m.\u001b[39mstrftime(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mY\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mm\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mH\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mM\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mS\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 4\u001b[0m callbacks \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTensorBroad\u001b[49m(log_dir \u001b[38;5;241m=\u001b[39m logsData, histogram_freq\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'keras.api._v2.keras.callbacks' has no attribute 'TensorBroad'"
     ]
    }
   ],
   "source": [
    "import datetime \n",
    "import tensorflow as tf\n",
    "logsData = \"logs/fit\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "callbacks = tf.keras.callbacks.TensorBroad(log_dir = logsData, histogram_freq=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4faeaa2a-d88e-4cdd-85e7-adebd77f23d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X_train, Y_train, epochs= 10, validation_data = (X_test,Y_test), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a5a2207-18fc-465e-8b1a-6354c906b577",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"Models/CatsandDogs.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a2619ec-401e-40fc-83b2-1ce2766ccdcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_data = [\"cat\",\"dog\"]\n",
    "saveModelData = load_model(\"Models/CatsandDogs.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "67cfd117-0961-4c55-a014-47cbe2cc5e26",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ImageFeatureExtract' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [30]\u001b[0m, in \u001b[0;36m<cell line: 7>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m     gray \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mexpand_dims(gray,\u001b[38;5;241m2\u001b[39m) \u001b[38;5;66;03m#(28,28,1)\u001b[39;00m\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m gray\n\u001b[1;32m----> 7\u001b[0m testImageDataFeature \u001b[38;5;241m=\u001b[39m \u001b[43mImageFeatureExtract\u001b[49m(testImageData)\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m255.0\u001b[39m\n\u001b[0;32m      8\u001b[0m testImageDataFeature \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([testImageDataFeature])\n",
      "\u001b[1;31mNameError\u001b[0m: name 'ImageFeatureExtract' is not defined"
     ]
    }
   ],
   "source": [
    "testImageData = cv2.imread(\"C:/Users/Anik/Downloads/cat.jpeg\")\n",
    "testImageDataFeature = ImageFeatureExtract(testImageData)/255.0\n",
    "testImageDataFeature = np.array([testImageDataFeature])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4add4dce-9e83-42d6-ba0b-b5b728cb2e17",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'testImageDataFeature' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [27]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mtestImageDataFeature\u001b[49m\u001b[38;5;241m.\u001b[39mshape\n",
      "\u001b[1;31mNameError\u001b[0m: name 'testImageDataFeature' is not defined"
     ]
    }
   ],
   "source": [
    "testImageDataFeature.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "930ebc03-38f2-4a2d-aa6e-8b3ac2d28f9f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1593e56-5a77-4af0-937e-f53d48e5f6dc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
